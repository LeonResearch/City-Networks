{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02735667-9853-4d21-aa51-4b375022d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from torch_geometric.data import Data\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm \n",
    "\n",
    "from publib import set_style, fix_style\n",
    "\n",
    "from utils import (\n",
    "    compute_k_hop_homophily, \n",
    "    compute_k_hop_eccentricity,\n",
    "    compute_k_hop_euclidean,\n",
    "    create_partition_labels,\n",
    ")\n",
    "\n",
    "set_style(['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3a3aaf-0a2d-4ebd-8688-428af65661b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_hop=16\n",
    "n_chunks=10\n",
    "K=5\n",
    "\n",
    "dataset_name = \"paris\"\n",
    "dataset_path = f'./road_data/{dataset_name}'\n",
    "save_path = f\"./\"\n",
    "\n",
    "\n",
    "d_labels = {\n",
    "    \"paris\":\"Paris\", \"shanghai\":\"Shanghai\", \"la\":\"L.A.\", \"london\":\"London\",\n",
    "}\n",
    "\n",
    "d_color = {\n",
    "    \"paris\":\"#c5373e\", # Red, \"#9c251c\", rgb(197, 55, 62)\n",
    "    \"shanghai\":   \"#006eae\", # Blue, \"#00498d\", rgb(0, 110, 174)\n",
    "    \"la\":  \"#439130\", # Green, \"#1c6e2b\",   rgb(67, 145, 48)\n",
    "    \"london\":   \"#6e788e\", # Grey # \"#43536a\",   rgb(110, 120, 142)\n",
    "}\n",
    "\n",
    "d_marker = {\"paris\":'x', \"shanghai\":'o', \"la\":'^', \"london\":\"s\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747b1bf0-33c0-47b3-8036-4e10277c3cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labels by splitting data into 10 chunks\n",
      "Creating labels by splitting data into 10 chunks\n",
      "Creating labels by splitting data into 10 chunks\n",
      "Creating labels by splitting data into 10 chunks\n"
     ]
    }
   ],
   "source": [
    "homophily_scores = {}\n",
    "k_hop_distances_dict = {}\n",
    "label_dict = {}\n",
    "eccentricities = {}\n",
    "sampled_nodes = {}\n",
    "euclidean_distances = {}\n",
    "\n",
    "compute_homophily = False\n",
    "compute_eccentricity = False\n",
    "compute_euclidean = False\n",
    "\n",
    "for dataset_name in [\"paris\", \"shanghai\", \"la\", \"london\"]:\n",
    "    dataset_path = f'./road_data/{dataset_name}'\n",
    "    k_hop_distances = torch.load(f'{dataset_path}/node_labels_nhop-{k_hop}.pt')\n",
    "    node_feat = torch.load(f'{dataset_path}/node_features.pt')\n",
    "    edge_feat = torch.load(f'{dataset_path}/edge_features.pt')\n",
    "    edge_index = torch.load(f'{dataset_path}/edge_indices.pt')\n",
    "    k_hop_distances_dict[dataset_name] = k_hop_distances\n",
    "    \n",
    "    label = create_partition_labels(k_hop_distances, n_chunks)\n",
    "    label_dict[dataset_name] = label\n",
    "    label = torch.nn.functional.one_hot(label, num_classes=n_chunks)\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    sample_size = 1000\n",
    "    num_nodes = torch.max(edge_index).item() + 1  # Total number of nodes\n",
    "    random_samples = torch.randperm(num_nodes)[:sample_size]  # Randomly sample nodes\n",
    "\n",
    "    if compute_euclidean:\n",
    "        euclidean_distances[dataset_name], sampled_nodes[dataset_name] = compute_k_hop_euclidean(\n",
    "            node_feat,\n",
    "            edge_index, \n",
    "            edge_weight=edge_feat[:,0], \n",
    "            k=k_hop, \n",
    "            node_samples=random_samples,\n",
    "            sample_rate=0.1\n",
    "        )\n",
    "\n",
    "    if compute_eccentricity:\n",
    "        eccentricities[dataset_name], sampled_nodes[dataset_name] = compute_k_hop_eccentricity(\n",
    "            edge_index, \n",
    "            edge_weight=edge_feat[:,0], \n",
    "            k=k_hop, \n",
    "            node_samples=random_samples,\n",
    "            sample_rate=0.1\n",
    "        )\n",
    "\n",
    "    if compute_homophily:\n",
    "        data = Data(y=label, edge_index=edge_index)\n",
    "        mask = torch.ones(label.shape[0]).long()\n",
    "        \n",
    "        score = compute_k_hop_homophily(data.y, data.edge_index, mask, K, sampling_rate=0.1)\n",
    "        homophily_scores[dataset_name] = score\n",
    "        print(f\"Homophily score for {dataset_name} is: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946863be",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {}\n",
    "for dataset_name in [\"paris\", \"shanghai\", \"la\", \"london\"]:\n",
    "    x1 = torch.tensor(euclidean_distances[dataset_name])\n",
    "    x2 = torch.tensor(eccentricities[dataset_name]) / 1000 # Change from meters to km\n",
    "    mask = x1>=0\n",
    "    x1, x2 = x1[mask], x2[mask]\n",
    "    corr, _ = pearsonr(x1, x2)\n",
    "    correlations[dataset_name] = [x1.tolist(), x2.tolist(), corr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb5b70-cf03-485c-b518-788a02f11885",
   "metadata": {},
   "source": [
    "n_chunk=10 {'paris': 0.43517953157424927, 'shanghai': 0.4792105555534363, 'la': 0.46932077407836914, 'london': 0.47633564472198486}\n",
    "\n",
    "n_chunk=20 {'paris': 0.5819949507713318,  'shanghai': 0.5968075394630432 \n",
    " 'la': 0.5921060442924 \n",
    " 'london': 0.5986458659172058}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e7d03a-e8e7-4f37-af2d-3765fcb9caea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m26\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create the figure and axis\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot histograms for each dataset on the same subplot\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshanghai\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mla\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlondon\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "num_bins = 50\n",
    "fontsize = 26\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Plot histograms for each dataset on the same subplot\n",
    "for dataset_name in [\"paris\", \"shanghai\", \"la\", \"london\"]:\n",
    "    ax[0].hist(\n",
    "        x=euclidean_distances[dataset_name],\n",
    "        bins=num_bins,\n",
    "        range=(0, 15),  # Limit the x-axis to focus on the main distribution\n",
    "        density=True,\n",
    "        alpha=0.7,\n",
    "        label=d_labels[dataset_name],\n",
    "        color=d_color[dataset_name],\n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "# Set labels and title\n",
    "ax[0].set_xlabel(\"Euclidean distance (km)\", fontsize=fontsize)\n",
    "ax[0].set_ylabel(\"Density\", fontsize=fontsize)\n",
    "ax[0].set_title(\"(a) Distributions of distance\", fontsize=fontsize + 2)\n",
    "ax[0].tick_params(axis='both', labelsize=fontsize - 3)\n",
    "ax[0].xaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "\n",
    "# Add gridlines for readability\n",
    "ax[0].grid(visible=True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add legend\n",
    "ax[0].legend(fontsize=fontsize - 5, frameon=True)\n",
    "\n",
    "\n",
    "for dataset_name in [\"paris\", \"shanghai\", \"la\", \"london\"]:\n",
    "    x1 = correlations[dataset_name][0][:200]\n",
    "    x2 = correlations[dataset_name][1][:200]\n",
    "    sns.regplot(\n",
    "        x=x1, y=x2, ax=ax[1],\n",
    "        ci=95, scatter=True, \n",
    "        color=d_color[dataset_name],\n",
    "        label=f\"{d_labels[dataset_name]}; Corr={correlations[dataset_name][2]:.2f}\",\n",
    "        line_kws={\n",
    "            \"linewidth\":3,\n",
    "        },\n",
    "        scatter_kws={\n",
    "            \"alpha\":0.6,\n",
    "        },\n",
    "        marker=d_marker[dataset_name]\n",
    "    )\n",
    "\n",
    "ax[1].set_xlim(-0.5, 8)\n",
    "ax[1].set_ylim(-0.5, 12)\n",
    "#ax[1].set_xticks([x for x in [0, 0.05, 0.10]])\n",
    "\n",
    "ax[1].set_xlabel(\"Euclidean distance (km)\", fontsize=fontsize)\n",
    "ax[1].set_ylabel(\"Eccentricity (km)\", fontsize=fontsize)\n",
    "ax[1].tick_params(axis='both', labelsize=fontsize - 3)\n",
    "ax[1].set_title(\"(b) Correlation plots\", fontsize=fontsize + 2)\n",
    "ax[1].legend(fontsize=fontsize - 6, frameon=True)\n",
    "ax[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Apply custom styling and adjust layout\n",
    "plt.tight_layout()\n",
    "fix_style('article')\n",
    "plt.savefig(f\"{save_path}/label_distance_distributions.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075437d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b4f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
